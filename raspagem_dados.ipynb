{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import wget\n",
    "import os\n",
    "import sys\n",
    "import win32com.client as win32\n",
    "from win32com.client import Dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Página de origem dos links - a ser raspada\n",
    "url = 'https://www.prefeitura.sp.gov.br/cidade/secretarias/transportes/institucional/sptrans/acesso_a_informacao/index.php?p=269652'\n",
    "\n",
    "#Fazer a requisição \n",
    "req = requests.get(url)\n",
    "req = req.text\n",
    "\n",
    "#aplicar o BS a requisição\n",
    "bs = BeautifulSoup(req, \"html.parser\") #print(bs.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpar o conteúdo da requisição: localiar tag a / classe calendários / e a tag a novamente dentro de calendário\n",
    "# avaliar se é possível simplificar esse processo.\n",
    "base = bs.find_all(class_='calendarios')\n",
    "for link in base:\n",
    "    base = link.find_all('a')\n",
    "\n",
    "#extrair os links\n",
    "base_aux = []\n",
    "for href in base:\n",
    "    base_aux.append(href.get('href'))\n",
    "    \n",
    "#consolidar somente os links em um DF\n",
    "for item in base_aux:\n",
    "    if 'Consolidado' in item:\n",
    "        base_aux.remove(item)\n",
    "base = pd.DataFrame(base_aux)\n",
    "\n",
    "#renomear a coluna\n",
    "base.columns = ['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BAIXAR PLANILHAS DO SITE\n",
    "# Esse passo foi necessario porque a planilha contem um resíduo/sujeira de macro, \n",
    "# que so aparece quando o arquivo é aberto pela primeira vez. \n",
    "# Inicialmente pretendia utilizar o urllib mas gerava um erro. \n",
    "#Somente com essa alternativa e a conversão do XLS para XLSX foi possível contornar o problema.\n",
    "\n",
    "for index, row in base.iterrows():\n",
    "    url_dia = row['link']\n",
    "    wget.download(url_dia, 'E:/user/2019inicio/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CONVERTER PLANILHAS DE XLS PARA XLSX\n",
    "\n",
    "#pasta inicial onde estao os arquivos\n",
    "dirname = r'E:/user/2019inicio'\n",
    "#pasta onde serao salvos os arquivos\n",
    "dirname_final = r'E:/user/2019final' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso tenha problemas com win32, uma referencia para consertar o problema\n",
    "#https://stackoverflow.com/questions/52889704/python-win32com-excel-com-model-started-generating-errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monta a aplicação para abir o Excel\n",
    "excel = win32.gencache.EnsureDispatch('Excel.Application')\n",
    "excel.DisplayAlerts = False\n",
    "excel.EnableEvents = False\n",
    "\n",
    "#Itera cada planilha no diretório onde os arquivos foram salvos\n",
    "for planilha in os.listdir(dirname):\n",
    "    \n",
    "    #Decode para permitir abrir o arquivo no proximo passo. Sem isso, estava tendo problema com o nome do arquivo\n",
    "    filename = os.fsdecode(planilha) \n",
    "    \n",
    "    #Utiliza a aplicação para abrir o arquivo, e duas configurações paa evitar prompt de mensagens\n",
    "    wb = excel.Workbooks.Open(dirname + '\\\\' + filename)\n",
    "    wb.DoNotPromptForConvert = True\n",
    "    wb.CheckCompatibility = False\n",
    "\n",
    "    #salva o conteudo da celula A1 como a variável nome\n",
    "    nome = str(wb.Sheets[1].Cells(4,1).Value)\n",
    "    nome = nome[:10]\n",
    "    \n",
    "    #deleta as outras abas da planilha\n",
    "    num = wb.Sheets.Count\n",
    "    if num >= 2:\n",
    "        wb.Sheets[2].Delete()\n",
    "            \n",
    "    #salva o arquivo em formato xlsx - 51, com a variavel nome, no diretório final\n",
    "    wb.SaveAs(dirname_final + '\\\\' + nome, FileFormat = 51)\n",
    "\n",
    "    wb.Close(SaveChanges=True)\n",
    "\n",
    "#desmota a Aplicacao\n",
    "excel.Application.Quit()\n",
    "del excel\n",
    "excel = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geral = pd.DataFrame()\n",
    "\n",
    "#Iterando em cada planilha\n",
    "for planilha_final in os.listdir(dirname_final):\n",
    "    filename = os.fsdecode(planilha_final)     \n",
    "    base = pd.read_excel(dirname_final + '\\\\' + filename, header=None)\n",
    "    \n",
    "    #Somente serão consolidados as 5 primeiras colunas e a última da planilha, que contem o total de passageiros.\n",
    "    #foi uma solução mais simples, porque as planilhas mudaram de formato ao longo do ano e fazer a correspondencias entre \n",
    "    # os dois modelos iria dar muito trabalho adicional\n",
    "    fim = len(base.columns) - 1\n",
    "    base_1 = base.iloc[:, [0, 1, 2, 3, 4, fim]]\n",
    "    base_1.columns = ['data', 'tipo', 'area', 'empresa', 'linha', 'passageiros']\n",
    "    \n",
    "    geral = pd.concat([geral, base_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como as planilhas original possuem uma primeira linha descritiva é preciso elimina-la. \n",
    "#E como o formato pode variar, não é recomendado fazer pela posição\n",
    "#Também elimina a linha em branco entre a primeira linha e o cabeçalho da tabela\n",
    "geral.dropna(axis=0, thresh=5, inplace=True)\n",
    "\n",
    "#Remover a cabeçalho original da tabela da planilha\n",
    "geral = geral[geral.linha != 'Linha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustado o campo de data\n",
    "geral['data'] = geral['data'].astype(str)\n",
    "\n",
    "#Corrigindo uma data onde consta 2018\n",
    "geral['data'] = geral['data'].str.replace('2018', '2019')\n",
    "\n",
    "#Convertendo em data\n",
    "geral['data'] = pd.to_datetime(geral['data'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvar em um csv\n",
    "geral.to_csv('base_2019.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
